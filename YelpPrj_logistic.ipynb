{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Final Project Yelp \n",
    "## Group Members: Haoning Liu, Jiaqi Chen, Mengqi Liu, Xiaolu Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-72-6.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BD4</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f65600c1748>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"BD4\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one of four data files 'review' from local\n",
    "review = pd.read_csv(\"/Users/lhnzm/yelp_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove comma, quotation mark, and changing line character from text column\n",
    "review['text'] = review['text'].str.replace(',', '')\n",
    "review['text'] = review['text'].str.replace('\"', '')\n",
    "review['text'] = review['text'].str.replace('\\r\\n', '')\n",
    "review['text'] = review['text'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out separating with comma and upload to S3 bucket\n",
    "review.to_csv('review1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in CSV files from S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = spark.read\\\n",
    "  .format('csv')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://bigdataclasslhn/Prj_Yelp/review1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review=review.drop('_c0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check unique values for each column and whether data has been read in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         business_id|\n",
      "+--------------------+\n",
      "|f4mh1Y0rnvbJRfQ3j...|\n",
      "|cKwg6HFaLYXl7Ar0r...|\n",
      "|jcpgiXF0PCyS9hrvq...|\n",
      "|R_M4P9XetEM-aLE7e...|\n",
      "|DEBqmgxv2yhJ93LqG...|\n",
      "|Cml4Yt5cTx64cOMan...|\n",
      "|bo3SQVtErnMOqO6lk...|\n",
      "|Cl-xl1vTUwHeaGgBx...|\n",
      "|oIEmXWLtoh5blz-iw...|\n",
      "|Op2IR4FffXZ5KXYFn...|\n",
      "|yB5FMuc9Y3oyhsOmu...|\n",
      "|cEqOh78v1g1RCWHyu...|\n",
      "|lt8IW9Bpy9GMeKGxy...|\n",
      "|uC3qwaxsOkdJzpOc0...|\n",
      "|686oeWNsbc-aczplC...|\n",
      "|gPuxh3HNvoVt8aWVW...|\n",
      "|mA27CG2U3ytmkxIGV...|\n",
      "|x6qH9HXhzuKM03jcZ...|\n",
      "|74LU6K2ro5AQXKT0J...|\n",
      "|TdefcbsFAj6WXHwlG...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('business_id').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76755"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.select('business_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|stars|\n",
      "+-----+\n",
      "| null|\n",
      "|    1|\n",
      "|    3|\n",
      "|    5|\n",
      "|    4|\n",
      "|    2|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('stars').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             user_id|\n",
      "+--------------------+\n",
      "|rs3pq6wRmaSIADCIn...|\n",
      "|xS6kmkMXp0PRrFwkS...|\n",
      "|aNOSjqQFsrfcgmFtO...|\n",
      "|-9da1xk7zgnnfO1uT...|\n",
      "|PLjruA-EMskWfirBU...|\n",
      "|O-frog8VhICKAT0gr...|\n",
      "|7o473jeLWW-zgKN-Q...|\n",
      "|L1XxGWFJ3S7xBQCT8...|\n",
      "|D2ljL5ejuqpa4f8fn...|\n",
      "|CzkWUMIYDxUSetfCR...|\n",
      "|5avk-VCo_6Bx65ct1...|\n",
      "|oKWVVqPWVzq5s6nS4...|\n",
      "|e5kxYMksMVWApEJdO...|\n",
      "|f-6oae7TltlfJicUi...|\n",
      "|NL9jmu5jSkCdMM-i9...|\n",
      "|z6gjzFENiQf-K3lPy...|\n",
      "|Al2g2P9gt057Julh1...|\n",
      "|midS4e50ZmuOeGyNm...|\n",
      "|yTr8nlIjQCJWc0ZIC...|\n",
      "|yb0AdKzhYwQIlt47r...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('user_id').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|useful|\n",
      "+------+\n",
      "|   148|\n",
      "|    31|\n",
      "|    85|\n",
      "|   251|\n",
      "|   808|\n",
      "|   137|\n",
      "|    65|\n",
      "|    53|\n",
      "|   255|\n",
      "|   970|\n",
      "|   133|\n",
      "|    78|\n",
      "|   362|\n",
      "|   108|\n",
      "|   155|\n",
      "|    34|\n",
      "|   193|\n",
      "|   101|\n",
      "|   126|\n",
      "|   115|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('useful').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|funny|\n",
      "+-----+\n",
      "|  148|\n",
      "|   31|\n",
      "|   85|\n",
      "|  137|\n",
      "|   65|\n",
      "|   53|\n",
      "|  970|\n",
      "|  133|\n",
      "|   78|\n",
      "|  322|\n",
      "|  108|\n",
      "|  155|\n",
      "|   34|\n",
      "|  101|\n",
      "|  115|\n",
      "|   81|\n",
      "|   28|\n",
      "|  183|\n",
      "|  412|\n",
      "|   76|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('funny').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               date|\n",
      "+-------------------+\n",
      "|2010-10-05 19:12:35|\n",
      "|2016-02-11 22:26:21|\n",
      "|2015-01-18 16:00:39|\n",
      "|2012-11-06 05:23:38|\n",
      "|2013-11-14 04:08:35|\n",
      "|2015-06-21 02:01:34|\n",
      "|2018-09-25 05:26:16|\n",
      "|2015-04-01 17:43:03|\n",
      "|2014-04-19 12:06:45|\n",
      "|2018-09-25 03:51:25|\n",
      "|2014-02-23 21:39:30|\n",
      "|2016-08-03 23:31:26|\n",
      "|2016-07-25 07:00:01|\n",
      "|2018-04-04 03:02:29|\n",
      "|2017-08-28 19:16:03|\n",
      "|2017-10-11 02:23:26|\n",
      "|2016-06-22 21:16:05|\n",
      "|2008-08-18 22:32:45|\n",
      "|2007-12-09 15:16:21|\n",
      "|2015-05-12 16:16:59|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('date').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = review.drop('review_id','text','date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = spark.read\\\n",
    "  .format('csv')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://bigdataclasslhn/Prj_Yelp/yelp_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = business.withColumnRenamed('stars', 'stars_business')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- stars_business: double (nullable = true)\n",
      " |-- review_count: double (nullable = true)\n",
      " |-- is_open: integer (nullable = true)\n",
      " |-- attributes.GoodForKids: string (nullable = true)\n",
      " |-- attributes.RestaurantsReservations: string (nullable = true)\n",
      " |-- attributes.GoodForMeal: string (nullable = true)\n",
      " |-- attributes.BusinessParking: string (nullable = true)\n",
      " |-- attributes.Caters: string (nullable = true)\n",
      " |-- attributes.NoiseLevel: string (nullable = true)\n",
      " |-- attributes.RestaurantsTableService: string (nullable = true)\n",
      " |-- attributes.RestaurantsTakeOut: string (nullable = true)\n",
      " |-- attributes.RestaurantsPriceRange2: string (nullable = true)\n",
      " |-- attributes.OutdoorSeating: string (nullable = true)\n",
      " |-- attributes.BikeParking: string (nullable = true)\n",
      " |-- attributes.Ambience: string (nullable = true)\n",
      " |-- attributes.HasTV: string (nullable = true)\n",
      " |-- attributes.WiFi: string (nullable = true)\n",
      " |-- attributes.Alcohol: string (nullable = true)\n",
      " |-- attributes.RestaurantsAttire: string (nullable = true)\n",
      " |-- attributes.RestaurantsGoodForGroups: string (nullable = true)\n",
      " |-- attributes.RestaurantsDelivery: string (nullable = true)\n",
      " |-- attributes.BusinessAcceptsCreditCards: string (nullable = true)\n",
      " |-- attributes.BusinessAcceptsBitcoin: string (nullable = true)\n",
      " |-- attributes.ByAppointmentOnly: string (nullable = true)\n",
      " |-- attributes.AcceptsInsurance: string (nullable = true)\n",
      " |-- attributes.Music: string (nullable = true)\n",
      " |-- attributes.GoodForDancing: string (nullable = true)\n",
      " |-- attributes.CoatCheck: string (nullable = true)\n",
      " |-- attributes.HappyHour: string (nullable = true)\n",
      " |-- attributes.BestNights: string (nullable = true)\n",
      " |-- attributes.WheelchairAccessible: string (nullable = true)\n",
      " |-- attributes.DogsAllowed: string (nullable = true)\n",
      " |-- attributes.BYOBCorkage: string (nullable = true)\n",
      " |-- attributes.DriveThru: string (nullable = true)\n",
      " |-- attributes.Smoking: string (nullable = true)\n",
      " |-- attributes.AgesAllowed: string (nullable = true)\n",
      " |-- attributes.HairSpecializesIn: string (nullable = true)\n",
      " |-- attributes.Corkage: string (nullable = true)\n",
      " |-- attributes.BYOB: string (nullable = true)\n",
      " |-- attributes.DietaryRestrictions: string (nullable = true)\n",
      " |-- attributes.Open24Hours: string (nullable = true)\n",
      " |-- attributes.RestaurantsCounterService: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- hours.Monday: string (nullable = true)\n",
      " |-- hours.Tuesday: string (nullable = true)\n",
      " |-- hours.Wednesday: string (nullable = true)\n",
      " |-- hours.Thursday: string (nullable = true)\n",
      " |-- hours.Friday: string (nullable = true)\n",
      " |-- hours.Saturday: string (nullable = true)\n",
      " |-- hours.Sunday: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = business.select('business_id','state','city','latitude','longitude',\"stars_business\",\"review_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- stars_business: double (nullable = true)\n",
      " |-- review_count: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip = spark.read\\\n",
    "  .format('csv')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://bigdataclasslhn/Prj_Yelp/yelp_tip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- compliment_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tip.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip = tip.select('user_id','business_id','compliment_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- compliment_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tip.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = spark.read\\\n",
    "  .format('csv')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://bigdataclasslhn/Prj_Yelp/yelp_user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = user.withColumnRenamed('useful','useful_user')\\\n",
    ".withColumnRenamed('funny','funny_user')\\\n",
    ".withColumnRenamed('cool','cool_user')\\\n",
    ".withColumnRenamed('review_count','review_count_user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = user.select('user_id','average_stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data by business ID and user ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined1 = review.join(business, on='business_id', how='left_outer')\n",
    "#combined1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined2 = combined1.join(user, on='user_id', how='left_outer')\n",
    "#combined2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print schema of combined data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- stars_business: double (nullable = true)\n",
      " |-- review_count: double (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliment_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined = combined2.join(tip, on=['business_id', 'user_id',], how='left_outer')\n",
    "combined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2555074"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for Logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check null value in stars column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|stars|  count|\n",
      "+-----+-------+\n",
      "| null|    134|\n",
      "|    1| 371228|\n",
      "|    3| 281425|\n",
      "|    5|1131301|\n",
      "|    4| 567828|\n",
      "|    2| 203158|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined.groupby(combined.stars).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows with nulls in stars column because the number of nulls is only 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.filter(combined.stars.isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert stars no more than 3 to 0 while stars more than 3 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = combined.withColumn('stars',when(combined.stars <= 3, '0').otherwise('1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count boolean values in stars column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|stars|  count|\n",
      "+-----+-------+\n",
      "|    0| 855811|\n",
      "|    1|1699129|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(df.stars).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pipeline and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the string fields to numeric ones\n",
    "stringIndexer_label = StringIndexer(inputCol=\"stars\", outputCol=\"label\",handleInvalid='keep')\n",
    "\n",
    "stringIndexer_city = StringIndexer(inputCol=\"city\", outputCol=\"city_SI\",handleInvalid='keep')\n",
    "stringIndexer_state = StringIndexer(inputCol=\"state\", outputCol=\"state_SI\",handleInvalid='keep')\n",
    "stringIndexer_compliment_count = StringIndexer(inputCol=\"compliment_count\", outputCol=\"compliment_count_SI\",handleInvalid='keep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at values for one of the re-encoded columns using fit method\n",
    "si_label_fit = StringIndexer(inputCol=\"stars\", outputCol=\"label\",handleInvalid='keep').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_label_fit.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorAssembler_de90272bd2bc"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a feature vector by combining all features together\n",
    "\n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols=[\"state_SI\", \n",
    "               \"city_SI\",\n",
    "               \"compliment_count_SI\", \n",
    "               \"useful\",\n",
    "               \"funny\",\n",
    "               \"cool\",\n",
    "               \"latitude\",\n",
    "               \"longitude\",\n",
    "               \"stars_business\",\n",
    "               \"review_count\",\n",
    "               \"average_stars\"], \n",
    "    outputCol=\"features\",\n",
    "    handleInvalid='keep')\n",
    "vectorAssembler_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index labels back to original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", \n",
    "                               outputCol=\"predictedLabel\", \n",
    "                               labels=stringIndexer_label.fit(df).labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector by combining all features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(stages=[stringIndexer_label,\n",
    "                               stringIndexer_state,\n",
    "                               stringIndexer_city,\n",
    "                               stringIndexer_compliment_count,\n",
    "                               vectorAssembler_features,\n",
    "                               lr,labelConverter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2 splits of combined data (train, test) by using the randomSplit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 2045032\n",
      "Number of testing records : 509908\n"
     ]
    }
   ],
   "source": [
    "splitted_data = df.randomSplit([0.8, 0.2])\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]\n",
    "\n",
    "print(\"Number of training records: \" + str(train_data.count()))\n",
    "print(\"Number of testing records : \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check schema of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- stars: string (nullable = false)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- stars_business: double (nullable = true)\n",
      " |-- review_count: double (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliment_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = pipeline_lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do predictions with testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lr.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area under the curve (AUC) for binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.818937\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluatorLR = BinaryClassificationEvaluator()\n",
    "accuracy = evaluatorLR.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
